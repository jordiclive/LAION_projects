#model_name_or_path: 't5-large'
model_name_or_path: 'EleutherAI/pythia-19m-deduped'
train_batch_size: 5
eval_batch_size: 6
logger: wandb
warmup_steps: 2000
learning_rate: 7e-4
num_train_epochs: 10
gradient_accumulation_steps: 5
num_workers: 8
adam_epsilon: 1e-8
data_path: '.'
wb_name: "test_saving"
wb_project: "OpenAssistant"
wb_entity: "jordanclive"
val_check_interval: 0.25
#skip_val: True
#limit_val_batches: None
label_smoothing: 0
max_seq_length: 512
max_target_length: 150
eval_max_gen_length: 150
num_sanity_val_steps: -1
test_outputs: outputs
eval_min_length: 5
generate: True
#offline: True
#gpus: 8
#visible_devices: "0,1,2,3,4,5,6,7"
#val_metric: 'rouge2'

gpus: 0
debug_mode: True
offline: True
local: True
# save_generations: True

#skip_val: True
#offline: True
#local: True
# load_checkpoint: True
#skip_val: False
